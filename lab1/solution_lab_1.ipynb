{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## TASK: IMDb scraping (deadline: 3 martie ora 23:59)\n",
    "\n",
    "First codeblock has all imports and global variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "import bs4\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_url = 'https://www.imdb.com/'\n",
    "url_top = base_url + 'chart/top/'\n",
    "headers = {\"Accept-Language\": \"en-US,en;q=0.5\"}\n",
    "# If you want to load more this has to be true, otherwise will do only first 25 reviews\n",
    "LOAD_MORE = True\n",
    "# Total reviews loaded for a single movie (50 implies only one load more request)\n",
    "TOTAL_LOADED = 50\n",
    "# loads only first 10 movies' reviews\n",
    "FAST_RUN = True\n",
    "\n",
    "def parse_html(html):\n",
    "    return bs4.BeautifulSoup(html, 'html.parser')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Pornind de la lista cu cele mai populare 250 de filme de pe IMDb ([https://www.imdb.com/chart/top/](https://www.imdb.com/chart/top/)), identificati pentru toate aceste filme link-ul catre pagina sa de recenzii.\n",
    "\n",
    "Exemplu: aici se gaseste pagina cu recenzii pentru \"The Shawshank Redemption\": [https://www.imdb.com/title/tt0111161/reviews](https://www.imdb.com/title/tt0111161/reviews)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "\n",
    "def get_titles(url):\n",
    "    html = requests.get(url, headers=headers).content\n",
    "    soup = parse_html(html)\n",
    "    top_entry_title = soup.select(\"table.chart.full-width tbody.lister-list tr td.titleColumn\")\n",
    "    for entry in top_entry_title:\n",
    "        url_title = entry.select_one(\"a\")[\"href\"]\n",
    "        print(url_title)\n",
    "\n",
    "\n",
    "def get_data(url):\n",
    "    \"\"\"\n",
    "    Gets all the titles in the top 250 from IMDB\n",
    "    :param url:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    html = requests.get(url, headers=headers).content\n",
    "    soup = parse_html(html)\n",
    "    top_entry_title = soup.select(\"table.chart.full-width tbody.lister-list tr\")\n",
    "    data = {\n",
    "        \"rank\": [],\n",
    "        \"title\": [],\n",
    "        \"year\": [],\n",
    "        \"rating\": [],\n",
    "        \"ratings_number\": [],\n",
    "        \"url_title\": [],\n",
    "        \"url_image\": []\n",
    "    }\n",
    "\n",
    "    for entry in top_entry_title:\n",
    "        columns = [column for column in entry.select(\"td\")]\n",
    "\n",
    "        # getting urls\n",
    "        try:\n",
    "            url_image = columns[0].select_one(\"a\").select_one(\"img\")[\"src\"]\n",
    "            url_title = columns[1].select_one(\"a\")[\"href\"]\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # getting rank, title and year\n",
    "        details = list(columns[1].stripped_strings)\n",
    "        rank = re.sub('\\.', '', details[0])\n",
    "        title = details[1]\n",
    "        year = re.sub('\\(|\\)', '', details[2])\n",
    "\n",
    "        # getting rating and number ratings\n",
    "        rating_data = columns[2].select_one(\"strong\")['title']\n",
    "        pattern = re.compile(\"[+-]?((\\d+[\\.\\,])+)?\\d+\")\n",
    "        rating_numbers = []\n",
    "        for matching in pattern.finditer(rating_data):\n",
    "            rating_numbers.append(matching.group())\n",
    "        rating_score = rating_numbers[0]\n",
    "        ratings_number = rating_numbers[1]\n",
    "\n",
    "        # putting all data in dictionary\n",
    "        data[\"rank\"].append(rank)\n",
    "        data[\"title\"].append(title)\n",
    "        data[\"year\"].append(year)\n",
    "        data[\"rating\"].append(rating_score)\n",
    "        data[\"ratings_number\"].append(ratings_number)\n",
    "        data[\"url_title\"].append(url_title)\n",
    "        data[\"url_image\"].append(url_image)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# pd_data = get_data(url_top)\n",
    "# pd_data.describe()\n",
    "# pd_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Pentru fiecare film colectati date despre recenziile sale (titlu, text, rating, data, utlizator, etc.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "def extract_text_from_element(element:bs4.BeautifulSoup):\n",
    "    value = None\n",
    "    if element is not None:\n",
    "        value = element.text.strip()\n",
    "    return value\n",
    "\n",
    "def extract_review_data(review_data: bs4.BeautifulSoup):\n",
    "    \"\"\"\n",
    "    This gets the whole div.lister data and extracts the next load_more key and all the current reviews\n",
    "    :param review_data: -- soup type object that has the div.lister data\n",
    "    :return:            -- returns review_data(pd.DataFrame) and data_key\n",
    "    \"\"\"\n",
    "    data_key = review_data.select_one(\"div.load-more-data\")['data-key']\n",
    "    data_review = review_data.select(\"div.lister-list div.review-container div.lister-item-content\")\n",
    "\n",
    "    data = {\n",
    "        \"title\": [],\n",
    "        \"text\": [],\n",
    "        \"rating\": [],\n",
    "        \"user\": [],\n",
    "        \"date\": []\n",
    "    }\n",
    "\n",
    "    for review in data_review:\n",
    "        # getting the rating\n",
    "        rating_element = review.select_one(\"div.ipl-ratings-bar span.rating-other-user-rating span\", class_=False)\n",
    "        rating = extract_text_from_element(rating_element)\n",
    "\n",
    "        # getting the title\n",
    "        title_element = review.select_one(\"a.title\")\n",
    "        title = extract_text_from_element(title_element)\n",
    "\n",
    "        # getting the username and date\n",
    "        user_date_data = review.select(\"div.display-name-date > span\")\n",
    "        user = extract_text_from_element(user_date_data[0])\n",
    "        date = extract_text_from_element(user_date_data[1])\n",
    "\n",
    "        # getting the text\n",
    "        text_element = review.select_one(\"div.content > div.text\")\n",
    "        text = extract_text_from_element(text_element)\n",
    "\n",
    "        data[\"title\"].append(title)\n",
    "        data[\"text\"].append(text)\n",
    "        data[\"rating\"].append(rating)\n",
    "        data[\"user\"].append(user)\n",
    "        data[\"date\"].append(date)\n",
    "    return pd.DataFrame(data), data_key\n",
    "\n",
    "def get_reviews(title_url, load_more=False, total_loaded=50):\n",
    "    \"\"\"\n",
    "    Gets the reviews given a movie title as a panda dataframe\n",
    "    :param title_url:       the url used in the link\n",
    "    :param load_more:       boolean whether we load more than once reviews (basically we press the load more button)\n",
    "    :param total_loaded:    number of reviews loaded in total\n",
    "    :return:                returns all the reviews as panda dataframe\n",
    "    \"\"\"\n",
    "    review_url = base_url + title_url + 'reviews/'\n",
    "    html = requests.get(review_url, headers=headers).content\n",
    "    soup = parse_html(html)\n",
    "\n",
    "    # getting the title of the movie\n",
    "    title_data = soup.select_one(\"section.article div.subpage_title_block\")\n",
    "    movie_title = title_data.select_one(\"div.subpage_title_block__right-column h3 a\").text\n",
    "\n",
    "    # getting the review data\n",
    "    review_data = soup.select_one(\"section.article div.lister\")\n",
    "    total_data, next_key = extract_review_data(review_data)\n",
    "\n",
    "    if load_more:\n",
    "        current_loaded = total_data.shape[0]\n",
    "        while current_loaded < total_loaded:\n",
    "            more_reviews = review_url + \"_ajax?ref_=undefined&paginationKey=\" + next_key\n",
    "            reviews_html = requests.get(more_reviews, headers=headers).content\n",
    "            more_review_data = parse_html(reviews_html).select_one(\"div\")\n",
    "            new_data, next_key = extract_review_data(more_review_data)\n",
    "            total_data = pd.concat([total_data, new_data])\n",
    "            current_loaded += new_data.shape[0]\n",
    "\n",
    "        # limit the total_data to correspond to the total_loaded param\n",
    "        total_data = total_data[: total_loaded]\n",
    "\n",
    "    total_data['movie_title'] = movie_title\n",
    "\n",
    "    return total_data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Creati un dataset de recenzii, pentru fiecare recenzie stocati:\n",
    " * filmul caruia ii apartine\n",
    " * titlul recenziei\n",
    " * textul recenziei\n",
    " * ratingul\n",
    " * data\n",
    " * utilizator\n",
    "\n",
    " Salvati datasetul intr-un fisier JSON.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_titles_reviews(links, load_more=True, total_loaded=50, fast_run=True):\n",
    "    \"\"\"\n",
    "    get all the movie data\n",
    "    :param total_loaded: total loaded reviews for each movie\n",
    "    :param links:       all links to the movies\n",
    "    :param load_more:   if we want to request more, basically pressing \"load more\"\n",
    "    :param fast_run:    reads only first 10 movies, so it runs faster\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    length = len(links) // 25 if fast_run else len(links)\n",
    "    for link_index in tqdm(range(length)):\n",
    "        title_url = links[link_index]\n",
    "        review_data = get_reviews(title_url, load_more=load_more, total_loaded=total_loaded)\n",
    "        all_data.append(review_data)\n",
    "    return pd.concat(all_data)\n",
    "\n",
    "\n",
    "# getting all data from top 250 movies\n",
    "top_data = get_data(url_top)\n",
    "# getting all titles from top 250 link\n",
    "titles_url = top_data['url_title'].to_numpy()\n",
    "\n",
    "# here if we want to, we can do a join between movie title and review movie title\n",
    "# so that each review has all data about movie\n",
    "\n",
    "# global params that can be changed from first codeblock\n",
    "all_reviews = get_titles_reviews(\n",
    "    links=titles_url,\n",
    "    load_more=LOAD_MORE,\n",
    "    total_loaded=TOTAL_LOADED,\n",
    "    fast_run=FAST_RUN\n",
    ")\n",
    "json_str = all_reviews.to_json(orient='records')\n",
    "json_result = json.loads(json_str)\n",
    "\n",
    "with open('reviews_data.json', 'w', encoding='utf8') as fout:\n",
    "    json.dump(json_result, fout, indent=4, sort_keys=True, ensure_ascii=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Pe o pagina cu recenzii putem gasi un numar mic de astfel de date. Butonul de \"Load more\" de la final, cand este apasat, produce un request care returneaza HTML-ul urmatoarelor recenzii. Folosind aceasta logica colectati automat pentru fiecare film un numar mai mare de recenzii."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "data": {
      "text/plain": "  rank                     title  year rating ratings_number  \\\n0    1  The Shawshank Redemption  1994    9.2      2,545,876   \n1    2             The Godfather  1972    9.1      1,751,329   \n2    3    The Godfather: Part II  1974    9.0      1,214,561   \n3    4           The Dark Knight  2008    9.0      2,496,211   \n4    5              12 Angry Men  1957    8.9        752,273   \n\n           url_title                                          url_image  \n0  /title/tt0111161/  https://m.media-amazon.com/images/M/MV5BMDFkYT...  \n1  /title/tt0068646/  https://m.media-amazon.com/images/M/MV5BM2MyNj...  \n2  /title/tt0071562/  https://m.media-amazon.com/images/M/MV5BMWMwMG...  \n3  /title/tt0468569/  https://m.media-amazon.com/images/M/MV5BMTMxNT...  \n4  /title/tt0050083/  https://m.media-amazon.com/images/M/MV5BMWU4N2...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>title</th>\n      <th>year</th>\n      <th>rating</th>\n      <th>ratings_number</th>\n      <th>url_title</th>\n      <th>url_image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>The Shawshank Redemption</td>\n      <td>1994</td>\n      <td>9.2</td>\n      <td>2,545,876</td>\n      <td>/title/tt0111161/</td>\n      <td>https://m.media-amazon.com/images/M/MV5BMDFkYT...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>The Godfather</td>\n      <td>1972</td>\n      <td>9.1</td>\n      <td>1,751,329</td>\n      <td>/title/tt0068646/</td>\n      <td>https://m.media-amazon.com/images/M/MV5BM2MyNj...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>The Godfather: Part II</td>\n      <td>1974</td>\n      <td>9.0</td>\n      <td>1,214,561</td>\n      <td>/title/tt0071562/</td>\n      <td>https://m.media-amazon.com/images/M/MV5BMWMwMG...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>The Dark Knight</td>\n      <td>2008</td>\n      <td>9.0</td>\n      <td>2,496,211</td>\n      <td>/title/tt0468569/</td>\n      <td>https://m.media-amazon.com/images/M/MV5BMTMxNT...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>12 Angry Men</td>\n      <td>1957</td>\n      <td>8.9</td>\n      <td>752,273</td>\n      <td>/title/tt0050083/</td>\n      <td>https://m.media-amazon.com/images/M/MV5BMWU4N2...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I've changed the function from point 2 to accept the specific length\n",
    "# - using the load_more param\n",
    "\n",
    "# Take a look at top_data (data collected from top 250 page) and all_reviews\n",
    "top_data.head()\n",
    "# all_reviews.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}